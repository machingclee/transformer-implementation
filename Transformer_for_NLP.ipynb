{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "ZbcvtPlp3YWu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 2**13\n",
    "MAX_SEQUENCE_LENGTH = 20\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9JJ7FBw84tG"
   },
   "source": [
    "# Stage 1: Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "P6o_cpZz3y_-"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    pass\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQN8jwx48_yU"
   },
   "source": [
    "# Stage 2: Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPlOT-2mlw0r"
   },
   "source": [
    "## Loading files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCD9jwXsLwS_"
   },
   "source": [
    "We import files from our personal google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "q8Or0sLV5b8t"
   },
   "outputs": [],
   "source": [
    "def text_gen(file_path):\n",
    "    with open(file_path, mode='r', encoding='utf-8') as f:\n",
    "        return (row for row in f.readlines()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEFw0D2vP_Dl"
   },
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwIBeGXn7LIJ"
   },
   "source": [
    "Getting the non_breaking_prefixes as a clean list of words with a point at the end so it is easier to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "L_TeuktU40Cb"
   },
   "outputs": [],
   "source": [
    "with open(\"./nonbreaking_prefix.en\",\n",
    "          mode='r',\n",
    "          encoding='utf-8') as f:\n",
    "    non_breaking_prefix_en = f.read()\n",
    "with open(\"./nonbreaking_prefix.fr\",\n",
    "          mode='r',\n",
    "          encoding='utf-8') as f:\n",
    "    non_breaking_prefix_fr = f.read()\n",
    "\n",
    "non_breaking_prefix_en = non_breaking_prefix_en.split(\"\\n\")\n",
    "non_breaking_prefix_en = [' ' + pref + '.' for pref in non_breaking_prefix_en]\n",
    "non_breaking_prefix_fr = non_breaking_prefix_fr.split(\"\\n\")\n",
    "non_breaking_prefix_fr = [' ' + pref + '.' for pref in non_breaking_prefix_fr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9x4mZfKMaxD"
   },
   "source": [
    "We will need each word and other symbol that we want to keep to be in lower case and separated by spaces so we can \"tokenize\" them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Qg-8LLK-WdFp"
   },
   "outputs": [],
   "source": [
    "# prepare generator for extremely large text file\n",
    "\n",
    "def reset_generators():\n",
    "    europarl_en = text_gen(\"./europarl-v7.fr-en.en\")\n",
    "    europarl_fr = text_gen(\"./europarl-v7.fr-en.fr\")\n",
    "\n",
    "    corpus_en = europarl_en\n",
    "\n",
    "    for prefix in non_breaking_prefix_en:\n",
    "        corpus_en = (row.replace(prefix, prefix + \"###\") for row in corpus_en)\n",
    "\n",
    "    corpus_en = (re.sub(r\"\\.(?=[0-9a-zA-Z])\", \".###\", row) for row in corpus_en)    \n",
    "    corpus_en = (re.sub(\".###\", \"\", row) for row in corpus_en)\n",
    "    corpus_en = (re.sub(r\"\\s+\", \" \", row) for row in corpus_en)\n",
    "    corpus_en = (\"<sos> \" + row + \" <eos>\" for row in corpus_en)\n",
    "\n",
    "    corpus_fr = europarl_fr\n",
    "\n",
    "    for prefix in non_breaking_prefix_en:\n",
    "        corpus_fr = (row.replace(prefix, prefix + \"###\") for row in corpus_fr)\n",
    "\n",
    "    corpus_fr = (re.sub(r\"\\.(?=[0-9a-zA-Z])\", \".###\", row) for row in corpus_fr)    \n",
    "    corpus_fr = (re.sub(\".###\", \"\", row) for row in corpus_fr)\n",
    "    corpus_fr = (re.sub(r\"\\s+\", \" \", row) for row in corpus_fr)\n",
    "    corpus_fr = (\"<sos> \" + row + \" <eos>\"  for row in corpus_fr)\n",
    "    \n",
    "    return corpus_en, corpus_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_en, corpus_fr = reset_generators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gen_length(gen):\n",
    "    return len(list(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007723 2007723\n"
     ]
    }
   ],
   "source": [
    "print(get_gen_length(corpus_en), get_gen_length(corpus_fr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-Y9v8-Tozl2"
   },
   "source": [
    "## Tokenizing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "p5YXanmOd_xK"
   },
   "outputs": [],
   "source": [
    "tokenizer_en = Tokenizer(num_words=MAX_VOCAB_SIZE, filters=\"\")\n",
    "tokenizer_fr = Tokenizer(num_words=MAX_VOCAB_SIZE, filters=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ftIbPzIwCtwL"
   },
   "outputs": [],
   "source": [
    "corpus_en, corpus_fr = reset_generators()\n",
    "tokenizer_en.fit_on_texts(corpus_en)\n",
    "tokenizer_fr.fit_on_texts(corpus_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192 8192\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE_EN = min(MAX_VOCAB_SIZE, len(tokenizer_en.word_index))\n",
    "VOCAB_SIZE_FR = min(MAX_VOCAB_SIZE, len(tokenizer_fr.word_index))\n",
    "print(VOCAB_SIZE_EN, VOCAB_SIZE_FR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "oPFe2YJDC9jw"
   },
   "outputs": [],
   "source": [
    "corpus_en, corpus_fr = reset_generators()\n",
    "input_sentences = tokenizer_en.texts_to_sequences(corpus_en)\n",
    "output_sentences = tokenizer_fr.texts_to_sequences(corpus_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192\n"
     ]
    }
   ],
   "source": [
    "indexes = set()\n",
    "\n",
    "for input_seq in input_sentences:\n",
    "    indexes.update(input_seq)\n",
    "\n",
    "print(len(indexes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark\n",
    "Even we have fed in the parameter ```num_words=MAX_VOCAB_SIZE``` in the constructor of ```Tokenizer```, both ```len(tokenizer_en.word_index)``` and ```len(tokenizer_fr.word_index)``` still exceed ```MAX_VOCAB_SIZE```. \n",
    "\n",
    "However, the number of output indexes in the text to seq transformation still agress with the number ```MAX_VOCAB_SIZE```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bG6AlcFMpC5C"
   },
   "source": [
    "## Remove too long sentences and do padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentences = pad_sequences(\n",
    "    input_sentences, \n",
    "    maxlen=MAX_SEQUENCE_LENGTH, \n",
    "    padding=\"post\"\n",
    ")\n",
    "\n",
    "output_sentences = pad_sequences(\n",
    "    output_sentences, \n",
    "    maxlen=MAX_SEQUENCE_LENGTH, \n",
    "    padding=\"post\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2007723, 20) (2007723, 20)\n"
     ]
    }
   ],
   "source": [
    "print(input_sentences.shape, output_sentences.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ypm8h5aZQTZ1"
   },
   "source": [
    "## Inputs/outputs creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FP0WPsdM8hl"
   },
   "source": [
    "As we train with batches, we need each input to have the same length. We pad with the appropriate token, and we will make sure this padding token doesn't interfere with our training later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "id": "nvDfLDWUONlE"
   },
   "outputs": [],
   "source": [
    "dataset = tensorflow.data.Dataset.from_tensor_slices((input_sentences, output_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "id": "wFxMp3TOIYff"
   },
   "outputs": [],
   "source": [
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tensorflow.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycT0YqydRcUd"
   },
   "source": [
    "# Stage 3: Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-SBoH8G4XyR9"
   },
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7G9C3ucmJ86I"
   },
   "source": [
    "Positional encoding formulae:\n",
    "\n",
    "$PE_{(pos,2i)} =\\sin(pos/10000^{2i/dmodel})$\n",
    "\n",
    "$PE_{(pos,2i+1)} =\\cos(pos/10000^{2i/dmodel})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2 2]\n",
      " [4 4 4]\n",
      " [6 6 6]]\n"
     ]
    }
   ],
   "source": [
    "# nuermical example:\n",
    "a = np.array([1,2,3])\n",
    "b = np.array([2,2,2])\n",
    "#shape: (3, 1), make 3 copies horizontally (so stack column by column)\n",
    "a = a[:, np.newaxis]\n",
    "#shape: (1, 3), make 3 copies vertically (so stack row by row)\n",
    "b = b[np.newaxis, :]\n",
    "\n",
    "print(a*b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "id": "e2wc6sYlX0dr"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "    \n",
    "    def get_angles(self, pos, i, d_model):\n",
    "        # pos of size (seg_length, 1) and \n",
    "        # i of size (1, d_model)\n",
    "        # pos * angles of size (seq_length, d_model)\n",
    "        angles = 1/np.power(10000., 2*(i//2)/np.float32(d_model))\n",
    "        return pos * angles\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        seq_length = inputs.shape.as_list()[-2]\n",
    "        d_model = inputs.shape.as_list()[-1]\n",
    "\n",
    "        angles = self.get_angles(\n",
    "            np.arange(seq_length)[:, np.newaxis],\n",
    "            np.arange(d_model)[np.newaxis, :],\n",
    "            d_model\n",
    "        )\n",
    "\n",
    "        angles[:, 0::2] = np.sin(angles[:, 0::2])\n",
    "        angles[:, 1::2] = np.cos(angles[:, 1::2]) \n",
    "        pos_encoding = angles[np.newaxis, ...]\n",
    "\n",
    "\n",
    "        return inputs + tf.cast(pos_encoding, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcw8YIQqRhOJ"
   },
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sffhwwvX-wj"
   },
   "source": [
    "### Attention computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VBuW6lESLDX"
   },
   "source": [
    "$\\mathrm{attention}(Q, K, V ) = \\left[\\mathrm{softmax}\\bigg(\\dfrac{QK^T}{\\sqrt{d_k}}\\bigg)\\right]V $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "id": "2rEoCNJURbrT"
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(queries, keys, values, mask):\n",
    "    product = tf.matmul(queries, keys, transpose_b=True)\n",
    "    keys_dim = tf.cast(tf.shape(keys)[-1], tf.float32)\n",
    "    scaled_product = product / tf.math.sqrt(keys_dim)\n",
    "    \n",
    "    if mask is not None:\n",
    "        scaled_product +=  mask * -1e9\n",
    "        \n",
    "    softmax = tf.nn.softmax(scaled_product, axis=-1)\n",
    "    attention = tf.matmul(softmax, values)\n",
    "    \n",
    "    return attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-MjtvXrfYEx7"
   },
   "source": [
    "### Multi-head attention sublayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "id": "lvq4I9uTX5p7"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(layers.Layer):\n",
    "    def __init__(self, n_proj):\n",
    "        self.n_proj = n_proj\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.d_model = input_shape[-1]  \n",
    "        assert self.d_model % self.n_proj == 0\n",
    "        \n",
    "        self.d_proj = self.d_model // self.n_proj\n",
    "        \n",
    "        self.query_lin = layers.Dense(units=self.d_model)\n",
    "        self.key_lin = layers.Dense(units=self.d_model)\n",
    "        self.value_lin = layers.Dense(units=self.d_model)\n",
    "        self.final_lin = layers.Dense(units=self.d_model)\n",
    "    \n",
    "    def split_proj(self, inputs, batch_size):\n",
    "        # inputs of shape: (batch_size, seq_length, d_model)\n",
    "        # split across the second dimension\n",
    "        shape = (batch_size,\n",
    "                -1,\n",
    "                 self.n_proj,\n",
    "                 self.d_proj\n",
    "                )\n",
    "        splited_inputs = tf.reshape(inputs, shape=shape)\n",
    "        \n",
    "        # desired output shape: \n",
    "        # (batch_size, n_proj, seq_length, d_proj)\n",
    "        return tf.transpose(\n",
    "            splited_inputs, \n",
    "            perm = [0, 2, 1, 3]\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def call(self, queries, keys, values, mask):\n",
    "        batch_size = tf.shape(queries)[0]\n",
    "        \n",
    "        queries = self.query_lin(queries)\n",
    "        keys = self.key_lin(keys)\n",
    "        values = self.value_lin(values)\n",
    "        \n",
    "        queries = self.split_proj(queries, batch_size)\n",
    "        keys = self.split_proj(keys, batch_size)\n",
    "        values = self.split_proj(values, batch_size)\n",
    "        \n",
    "        attention = scaled_dot_product_attention(\n",
    "            queries,\n",
    "            keys,\n",
    "            values,\n",
    "            mask\n",
    "        )\n",
    "        \n",
    "        # attention of shape:\n",
    "        # (batch_size, n_proj, d_proj, 1)\n",
    "\n",
    "        attention = tf.transpose(\n",
    "            attention,\n",
    "            perm=[0, 2, 1, 3]\n",
    "        )\n",
    "        \n",
    "        concat_attention = tf.reshape(\n",
    "            attention, \n",
    "            shape=(batch_size, -1, self.d_model)\n",
    "        )\n",
    "        \n",
    "        outputs = self.final_lin(concat_attention)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yiyuHe1OeT5N"
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "id": "UV0ZMH7KT_KZ"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(layers.Layer):\n",
    "    def __init__(self, FFN_units, n_proj, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.FFN_units = FFN_units\n",
    "        self.n_proj = n_proj\n",
    "        self.dropout = dropout\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.d_model = input_shape[-1]\n",
    "        self.multi_head_attention = MultiHeadAttention(self.n_proj)\n",
    "        self.dropout_1 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_1 = layers.LayerNormalization(epsilon = 1e-6)\n",
    "        \n",
    "        self.dense_1 = layers.Dense(units=self.FFN_units, activation=\"relu\")\n",
    "        self.dense_2 = layers.Dense(units=self.d_model)\n",
    "        self.dropout_2 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_2 = layers.LayerNormalization(epsilon = 1e-6)\n",
    "        \n",
    "    def call(self, inputs, mask, training):\n",
    "        attention = self.multi_head_attention(\n",
    "            inputs, \n",
    "            inputs, \n",
    "            inputs, \n",
    "            mask\n",
    "        )\n",
    "        \n",
    "        attention = self.dropout_1(attention, training=training)\n",
    "        attention = self.norm_1(attention + inputs)\n",
    "        \n",
    "        outputs = self.dense_1(attention)\n",
    "        outouts = self.dense_2(outputs)\n",
    "        outputs = self.dropout_2(outputs)\n",
    "        outputs = self.norm_2(tf.concat([outputs, attention], axis=-1))\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "id": "P-P92KeZih60"
   },
   "outputs": [],
   "source": [
    "class Encoder(layers.Layer):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 FFN_units,\n",
    "                 n_proj,\n",
    "                 dropout,\n",
    "                 vocab_size,\n",
    "                 d_model,\n",
    "                 name=\"encoder\"):\n",
    "        super(Encoder, self).__init__(name=name)\n",
    "        self.n_layers = n_layers\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.embedding = layers.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding()\n",
    "        self.dropout = layers.Dropout(rate=dropout)\n",
    "        self.enc_layers = [\n",
    "            EncoderLayer(FFN_units, n_proj, dropout)\n",
    "            for _ in range(n_layers)        \n",
    "        ]\n",
    "    \n",
    "    def call(self, inputs, mask, training):\n",
    "        outputs = self.embedding(inputs)\n",
    "        outputs = outputs * tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        outputs = self.pos_encoding(outputs)\n",
    "        outputs = self.dropout(outputs, training)\n",
    "        \n",
    "        for i in range(self.n_layers):\n",
    "            outputs = self.enc_layers[i](outputs, mask, training)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DthraBEwuvl"
   },
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "id": "7ZWZyFBnwy8u"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(layers.Layer):\n",
    "    def __init__(self, FFN_units, n_proj, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.FFN_units = FFN_units\n",
    "        self.n_proj = n_proj\n",
    "        self.dropout = dropout\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.d_model = input_shape[-1]\n",
    "        \n",
    "        self.multi_head_attention_1 = MultiHeadAttention(self.n_proj)\n",
    "        self.dropout_1 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.multi_head_attention_2 = MultiHeadAttention(self.n_proj)\n",
    "        self.dropout_2 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dense_1 = layers.Dense(units=self.FFN_units, activation=\"relu\")\n",
    "        self.dense_2 = layers.Dense(units=self.d_model)\n",
    "        self.dropout_3 = layers.Dropout(rate=self.dropout)\n",
    "        self.norm_3 = layers.LayerNormalization(epsilon=1e-6)\n",
    "    \n",
    "    def call(self, inputs, enc_outputs, mask_1, mask_2, training):\n",
    "        attention = self.multi_head_attention_1(\n",
    "            inputs, \n",
    "            inputs, \n",
    "            inputs,\n",
    "            mask_1\n",
    "        )\n",
    "        \n",
    "        attention = self.dropout_1(attention, training)\n",
    "        attention = self.norm_1(attention + inputs)\n",
    "        \n",
    "        attention_2 = self.multi_head_attention_2(\n",
    "            attention,\n",
    "            enc_outputs,\n",
    "            enc_outputs,\n",
    "            mask_2\n",
    "        )\n",
    "        \n",
    "        attention_2 = self.dropout_2(attention_2, training)\n",
    "        attention_2 = self.norm_2(attention_2 + attention)\n",
    "        \n",
    "        outputs = self.dense_1(attention_2)\n",
    "        outputs = self.dense_2(outputs)\n",
    "        outputs = self.dropout_3(outputs, training)\n",
    "        outputs = self.norm_3(tf.concat([outputs, attention_2], axis=-1))\n",
    "        \n",
    "        return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "id": "kpzdiWHiwywF"
   },
   "outputs": [],
   "source": [
    "class Decoder(layers.Layer):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 FFN_units,\n",
    "                 n_proj, \n",
    "                 dropout,\n",
    "                 vocab_size,\n",
    "                 d_model,\n",
    "                 name=\"decoder\"\n",
    "                ):\n",
    "        super(Decoder, self).__init__(name=name)\n",
    "        self.d_model = d_model\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = layers.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding()\n",
    "        self.dropout = layers.Dropout(rate=dropout)\n",
    "        \n",
    "        self.dec_layers = [\n",
    "            DecoderLayer(FFN_units, n_proj, dropout)\n",
    "            for _ in range(n_layers)\n",
    "        ]\n",
    "    \n",
    "    def call(self, inputs, enc_outputs, mask_1, mask_2, training):\n",
    "        outputs = self.embedding(inputs)\n",
    "        outputs = outputs * tf.math.sqrt(tf.cast(self.d_model, tf.float32))        \n",
    "        outputs = self.pos_encoding(outputs)\n",
    "        outputs = self.dropout(outputs, training)\n",
    "        \n",
    "        for i in range(self.n_layers):\n",
    "            outputs = self.dec_layers[i](\n",
    "                outputs,\n",
    "                enc_outputs,\n",
    "                mask_1,\n",
    "                mask_2,\n",
    "                training\n",
    "            )\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5sJYkjbz5DD"
   },
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "id": "GqvqNjJPwyh-"
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 vocab_size_enc,\n",
    "                 vocab_size_dec,\n",
    "                 d_model,\n",
    "                 n_layers,\n",
    "                 FFN_units,\n",
    "                 n_proj,\n",
    "                 dropout,\n",
    "                 name=\"transformer\"\n",
    "                ):\n",
    "        super(Transformer, self).__init__(name=name)\n",
    "        \n",
    "        self.encoder = Encoder(n_layers,\n",
    "                               FFN_units,\n",
    "                               n_proj, \n",
    "                               dropout, \n",
    "                               vocab_size_enc,\n",
    "                               d_model)\n",
    "        \n",
    "        self.decoder = Decoder(n_layers,\n",
    "                               FFN_units,\n",
    "                               n_proj,\n",
    "                               dropout,\n",
    "                               vocab_size_dec,\n",
    "                               d_model)\n",
    "        \n",
    "        self.last_linear = layers.Dense(units=vocab_size_dec)\n",
    "        \n",
    "    def create_padding_mask(self, seqs):\n",
    "        mask = tf.cast(tf.math.equal(seqs, 0), tf.float32)\n",
    "        return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "    def create_look_ahead_mask(self, seqs):\n",
    "        seq_len = tf.shape(seqs)[1]\n",
    "        look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "        return look_ahead_mask\n",
    "\n",
    "    def call(self, enc_inputs, dec_inputs, training):\n",
    "        enc_mask = self.create_padding_mask(enc_inputs)\n",
    "        dec_mask_1 = tf.maximum(\n",
    "            self.create_padding_mask(dec_inputs),\n",
    "            self.create_look_ahead_mask(dec_inputs)\n",
    "        )\n",
    "        dec_mask_2 = self.create_padding_mask(enc_inputs)\n",
    "        enc_outputs = self.encoder(enc_inputs, enc_mask, training)\n",
    "        dec_outputs = self.decoder(dec_inputs, enc_outputs, dec_mask_1, dec_mask_2, training)\n",
    "        outputs = self.last_linear(dec_outputs)\n",
    "\n",
    "        return outputs\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-c-LRThUPrso"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "id": "qiOdqQ5qPs8z"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "D_MODEL = 128\n",
    "N_LAYERS = 4\n",
    "FFN_UNITS = 512\n",
    "N_PROJ = 8\n",
    "DROPOUT = 0.1\n",
    "\n",
    "transformer = Transformer(vocab_size_enc=VOCAB_SIZE_EN,\n",
    "                        vocab_size_dec=VOCAB_SIZE_FR,\n",
    "                        d_model=D_MODEL,\n",
    "                        n_layers=N_LAYERS,\n",
    "                        FFN_units=FFN_UNITS,\n",
    "                        n_proj=N_PROJ,\n",
    "                        dropout=DROPOUT,\n",
    "                        name=\"transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "id": "46xg4Wrg1Wgl"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "id": "4Goque362343"
   },
   "outputs": [],
   "source": [
    "def loss_function(target, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(target, 0))\n",
    "    loss_ = loss_object(target, pred)  \n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ = loss_ * mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Nb_32PIU5Zkh",
    "outputId": "f3ea9cb2-bf36-4126-ade2-266dc6029528"
   },
   "outputs": [],
   "source": [
    "train_loss=tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"train_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "id": "lhFK5kUx602K"
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "        \n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "    \n",
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, \n",
    "    beta_1=0.9,\n",
    "    beta_2=0.98,\n",
    "    epsilon=1e-9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir_path = \"./checkpoints/\"\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(\n",
    "    model=transformer,\n",
    "    optimizer=optimizer\n",
    ")\n",
    "\n",
    "checkpoint_manager = tf.train.CheckpointManager(\n",
    "    checkpoint,\n",
    "    checkpoint_dir_path,\n",
    "    max_to_keep=5\n",
    ")\n",
    "\n",
    "if checkpoint_manager.latest_checkpoint:\n",
    "    checkpoint.restore(checkpoint_manager.latest_checkpoint)\n",
    "    print(\"[INFO] Latest checkpoint restored.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of epoch 1\n",
      "Epoch 1 Batch 0 Loss 5.6067 Accuracy 0.0584\n",
      "Epoch 1 Batch 50 Loss 5.5944 Accuracy 0.0555\n",
      "Epoch 1 Batch 100 Loss 5.5152 Accuracy 0.0594\n",
      "Epoch 1 Batch 150 Loss 5.4622 Accuracy 0.0690\n",
      "Epoch 1 Batch 200 Loss 5.4328 Accuracy 0.0756\n",
      "Epoch 1 Batch 250 Loss 5.4039 Accuracy 0.0797\n",
      "Epoch 1 Batch 300 Loss 5.3753 Accuracy 0.0829\n",
      "Epoch 1 Batch 350 Loss 5.3477 Accuracy 0.0855\n",
      "Epoch 1 Batch 400 Loss 5.3156 Accuracy 0.0883\n",
      "Epoch 1 Batch 450 Loss 5.2832 Accuracy 0.0912\n",
      "Epoch 1 Batch 500 Loss 5.2353 Accuracy 0.0946\n",
      "Epoch 1 Batch 550 Loss 5.1852 Accuracy 0.0982\n",
      "Epoch 1 Batch 600 Loss 5.1296 Accuracy 0.1017\n",
      "Epoch 1 Batch 650 Loss 5.0749 Accuracy 0.1054\n",
      "Epoch 1 Batch 700 Loss 5.0218 Accuracy 0.1091\n",
      "Epoch 1 Batch 750 Loss 4.9711 Accuracy 0.1128\n",
      "Epoch 1 Batch 800 Loss 4.9215 Accuracy 0.1164\n",
      "Epoch 1 Batch 850 Loss 4.8763 Accuracy 0.1198\n",
      "Epoch 1 Batch 900 Loss 4.8323 Accuracy 0.1230\n",
      "Epoch 1 Batch 950 Loss 4.7917 Accuracy 0.1261\n",
      "Epoch 1 Batch 1000 Loss 4.7535 Accuracy 0.1291\n",
      "Epoch 1 Batch 1050 Loss 4.7161 Accuracy 0.1321\n",
      "Epoch 1 Batch 1100 Loss 4.6803 Accuracy 0.1350\n",
      "Epoch 1 Batch 1150 Loss 4.6471 Accuracy 0.1378\n",
      "Epoch 1 Batch 1200 Loss 4.6138 Accuracy 0.1405\n",
      "Epoch 1 Batch 1250 Loss 4.5847 Accuracy 0.1430\n",
      "Epoch 1 Batch 1300 Loss 4.5548 Accuracy 0.1456\n",
      "Epoch 1 Batch 1350 Loss 4.5260 Accuracy 0.1480\n",
      "Epoch 1 Batch 1400 Loss 4.4993 Accuracy 0.1503\n",
      "Epoch 1 Batch 1450 Loss 4.4736 Accuracy 0.1526\n",
      "Epoch 1 Batch 1500 Loss 4.4479 Accuracy 0.1547\n",
      "Epoch 1 Batch 1550 Loss 4.4219 Accuracy 0.1568\n",
      "Epoch 1 Batch 1600 Loss 4.3988 Accuracy 0.1588\n",
      "Epoch 1 Batch 1650 Loss 4.3777 Accuracy 0.1607\n",
      "Epoch 1 Batch 1700 Loss 4.3566 Accuracy 0.1627\n",
      "Epoch 1 Batch 1750 Loss 4.3357 Accuracy 0.1645\n",
      "Epoch 1 Batch 1800 Loss 4.3148 Accuracy 0.1663\n",
      "Epoch 1 Batch 1850 Loss 4.2931 Accuracy 0.1680\n",
      "Epoch 1 Batch 1900 Loss 4.2737 Accuracy 0.1696\n",
      "Epoch 1 Batch 1950 Loss 4.2556 Accuracy 0.1711\n",
      "Epoch 1 Batch 2000 Loss 4.2373 Accuracy 0.1726\n",
      "Epoch 1 Batch 2050 Loss 4.2207 Accuracy 0.1740\n",
      "Epoch 1 Batch 2100 Loss 4.2040 Accuracy 0.1755\n",
      "Epoch 1 Batch 2150 Loss 4.1879 Accuracy 0.1769\n",
      "Epoch 1 Batch 2200 Loss 4.1727 Accuracy 0.1782\n",
      "Epoch 1 Batch 2250 Loss 4.1571 Accuracy 0.1796\n",
      "Epoch 1 Batch 2300 Loss 4.1421 Accuracy 0.1807\n",
      "Epoch 1 Batch 2350 Loss 4.1285 Accuracy 0.1818\n",
      "Epoch 1 Batch 2400 Loss 4.1153 Accuracy 0.1829\n",
      "Epoch 1 Batch 2450 Loss 4.1030 Accuracy 0.1840\n",
      "Epoch 1 Batch 2500 Loss 4.0901 Accuracy 0.1850\n",
      "Epoch 1 Batch 2550 Loss 4.0786 Accuracy 0.1860\n",
      "Epoch 1 Batch 2600 Loss 4.0680 Accuracy 0.1869\n",
      "Epoch 1 Batch 2650 Loss 4.0577 Accuracy 0.1877\n",
      "Epoch 1 Batch 2700 Loss 4.0474 Accuracy 0.1885\n",
      "Epoch 1 Batch 2750 Loss 4.0387 Accuracy 0.1891\n",
      "Epoch 1 Batch 2800 Loss 4.0301 Accuracy 0.1898\n",
      "Epoch 1 Batch 2850 Loss 4.0217 Accuracy 0.1904\n",
      "Epoch 1 Batch 2900 Loss 4.0130 Accuracy 0.1911\n",
      "Epoch 1 Batch 2950 Loss 4.0049 Accuracy 0.1918\n",
      "Epoch 1 Batch 3000 Loss 3.9980 Accuracy 0.1924\n",
      "Epoch 1 Batch 3050 Loss 3.9906 Accuracy 0.1930\n",
      "Epoch 1 Batch 3100 Loss 3.9834 Accuracy 0.1936\n",
      "Epoch 1 Batch 3150 Loss 3.9767 Accuracy 0.1941\n",
      "Epoch 1 Batch 3200 Loss 3.9699 Accuracy 0.1946\n",
      "Epoch 1 Batch 3250 Loss 3.9640 Accuracy 0.1950\n",
      "Epoch 1 Batch 3300 Loss 3.9589 Accuracy 0.1955\n",
      "Epoch 1 Batch 3350 Loss 3.9530 Accuracy 0.1959\n",
      "Epoch 1 Batch 3400 Loss 3.9474 Accuracy 0.1962\n",
      "Epoch 1 Batch 3450 Loss 3.9428 Accuracy 0.1965\n",
      "Epoch 1 Batch 3500 Loss 3.9382 Accuracy 0.1967\n",
      "Epoch 1 Batch 3550 Loss 3.9340 Accuracy 0.1969\n",
      "Epoch 1 Batch 3600 Loss 3.9302 Accuracy 0.1971\n",
      "Epoch 1 Batch 3650 Loss 3.9271 Accuracy 0.1973\n",
      "Epoch 1 Batch 3700 Loss 3.9234 Accuracy 0.1974\n",
      "Epoch 1 Batch 3750 Loss 3.9204 Accuracy 0.1976\n",
      "Epoch 1 Batch 3800 Loss 3.9177 Accuracy 0.1977\n",
      "Epoch 1 Batch 3850 Loss 3.9147 Accuracy 0.1979\n",
      "Epoch 1 Batch 3900 Loss 3.9121 Accuracy 0.1980\n",
      "Epoch 1 Batch 3950 Loss 3.9098 Accuracy 0.1980\n",
      "Epoch 1 Batch 4000 Loss 3.9077 Accuracy 0.1981\n",
      "Epoch 1 Batch 4050 Loss 3.9055 Accuracy 0.1982\n",
      "Epoch 1 Batch 4100 Loss 3.9035 Accuracy 0.1983\n",
      "Epoch 1 Batch 4150 Loss 3.9013 Accuracy 0.1984\n",
      "Epoch 1 Batch 4200 Loss 3.8994 Accuracy 0.1984\n",
      "Epoch 1 Batch 4250 Loss 3.8975 Accuracy 0.1985\n",
      "Epoch 1 Batch 4300 Loss 3.8955 Accuracy 0.1987\n",
      "Epoch 1 Batch 4350 Loss 3.8935 Accuracy 0.1988\n",
      "Epoch 1 Batch 4400 Loss 3.8916 Accuracy 0.1989\n",
      "Epoch 1 Batch 4450 Loss 3.8898 Accuracy 0.1990\n",
      "Epoch 1 Batch 4500 Loss 3.8883 Accuracy 0.1991\n",
      "Epoch 1 Batch 4550 Loss 3.8863 Accuracy 0.1992\n",
      "Epoch 1 Batch 4600 Loss 3.8843 Accuracy 0.1994\n",
      "Epoch 1 Batch 4650 Loss 3.8819 Accuracy 0.1995\n",
      "Epoch 1 Batch 4700 Loss 3.8796 Accuracy 0.1997\n",
      "Epoch 1 Batch 4750 Loss 3.8770 Accuracy 0.1999\n",
      "Epoch 1 Batch 4800 Loss 3.8744 Accuracy 0.2000\n",
      "Epoch 1 Batch 4850 Loss 3.8722 Accuracy 0.2002\n",
      "Epoch 1 Batch 4900 Loss 3.8699 Accuracy 0.2003\n",
      "Epoch 1 Batch 4950 Loss 3.8676 Accuracy 0.2004\n",
      "Epoch 1 Batch 5000 Loss 3.8651 Accuracy 0.2006\n",
      "Epoch 1 Batch 5050 Loss 3.8625 Accuracy 0.2007\n",
      "Epoch 1 Batch 5100 Loss 3.8598 Accuracy 0.2009\n",
      "Epoch 1 Batch 5150 Loss 3.8578 Accuracy 0.2010\n",
      "Epoch 1 Batch 5200 Loss 3.8553 Accuracy 0.2012\n",
      "Epoch 1 Batch 5250 Loss 3.8530 Accuracy 0.2014\n",
      "Epoch 1 Batch 5300 Loss 3.8511 Accuracy 0.2015\n",
      "Epoch 1 Batch 5350 Loss 3.8487 Accuracy 0.2016\n",
      "Epoch 1 Batch 5400 Loss 3.8466 Accuracy 0.2018\n",
      "Epoch 1 Batch 5450 Loss 3.8443 Accuracy 0.2019\n",
      "Epoch 1 Batch 5500 Loss 3.8420 Accuracy 0.2020\n",
      "Epoch 1 Batch 5550 Loss 3.8398 Accuracy 0.2021\n",
      "Epoch 1 Batch 5600 Loss 3.8379 Accuracy 0.2023\n",
      "Epoch 1 Batch 5650 Loss 3.8356 Accuracy 0.2024\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "for epoch in range (EPOCHS):\n",
    "    print(f\"start of epoch {epoch+1}\")\n",
    "    start = time.time()\n",
    "    \n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    for (batch, (enc_inputs, targets)) in enumerate(dataset):\n",
    "        dec_inputs = targets[:,:-1]\n",
    "        dec_outputs_real = targets[:, 1:]\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = transformer(enc_inputs, dec_inputs, True)\n",
    "            loss = loss_function(dec_outputs_real, predictions)\n",
    "        \n",
    "        gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "        optimizer.apply_gradients((\n",
    "            (grad, variable) \n",
    "            for (grad, variable) in zip(gradients, transformer.trainable_variables) if grad is not None))\n",
    "        \n",
    "        train_loss(loss)\n",
    "        train_accuracy(dec_outputs_real, predictions)\n",
    "        \n",
    "        if batch % 50 ==0:\n",
    "            print(\"Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}\".format(\n",
    "            epoch+1, batch, train_loss.result(), train_accuracy.result()))\n",
    "        \n",
    "    \n",
    "    checkpoint_save_path = checkpoint_manager.save()\n",
    "    print(\"Saving checkpoint for epoch {} at {}\".format(\n",
    "        epoch+1,\n",
    "        checkpoint_save_path\n",
    "    ))\n",
    "    \n",
    "    print(\"Time take for 1 epoch: {} secs \\n\".format(time.time()-start))               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmzyRwDrRGdq"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Transformer_for_NLP_udemy.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-2.4-cuda11] *",
   "language": "python",
   "name": "conda-env-tensorflow-2.4-cuda11-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
